Comandos para instalação do Docker Toolbox e Docker Machine:
==============================================================================

A) Instalando no Ubuntu

base=https://github.com/docker/machine/releases/download/v0.16.0 &&

curl -L $base/docker-machine-$(uname -s)-$(uname -m) >/tmp/docker-machine &&

sudo mv /tmp/docker-machine /usr/local/bin/docker-machine &&

chmod +x /usr/local/bin/docker-machine


Versão instalada do docker machine:
==============================================================================
root@dockerhost:~# docker-machine version
docker-machine version 0.16.0, build 702c267f

B) Instalando no Docker Tools no Windows 7 (64 Bits)

Acessar https://docs.docker.com/toolbox/toolbox_install_windows/ e seguir o procedimento.

Instalador: https://github.com/docker/toolbox/releases/download/v19.03.1/DockerToolbox-19.03.1.exe

Versão instalada do docker machine:
==============================================================================
pedro@phantro MINGW64 /c/Program Files/Docker Toolbox
$ docker version
Client:
 Version:           19.03.1
 API version:       1.40
 Go version:        go1.12.7
 Git commit:        74b1e89e8a
 Built:             Wed Jul 31 15:18:18 2019
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.12
  Git commit:       633a0ea838
  Built:            Wed Nov 13 07:28:45 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

pedro@phantro MINGW64 /c/Program Files/Docker Toolbox
$ docker-machine version
docker-machine.exe version 0.16.1, build cce350d7

pedro@phantro MINGW64 /c/Program Files/Docker Toolbox
$ docker-compose version
docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.0.2q  20 Nov 2018




Criando primeira VM com Docker machine
==============================================================================

1 - Listando as docker machines já existentes
docker-machine ls

$ docker-machine ls
NAME      ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
default   *        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5

pedro@phantro MINGW64 ~

pedro@phantro MINGW64 ~
$ docker-machine ls
NAME      ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
default   *        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5
vm1       -        virtualbox   Running   tcp://192.168.99.101:2376           v19.03.5

pedro@phantro MINGW64 ~


2 - Criando uma docker machine. 
docker-machine create -d virtualbox vm1

pedro@phantro MINGW64 ~
$ docker-machine create -d virtualbox vm1
Running pre-create checks...
Creating machine...
(vm1) Copying C:\Users\pedro\.docker\machine\cache\boot2docker.iso to C:\Users\pedro\.docker\machine\machines\vm1\boot2docker.iso...
(vm1) Creating VirtualBox VM...
(vm1) Creating SSH key...
(vm1) Starting the VM...
(vm1) Check network to re-create if needed...
(vm1) Waiting for an IP...
Waiting for machine to be running, this may take a few minutes...
Detecting operating system of created instance...
Waiting for SSH to be available...
Detecting the provisioner...
Provisioning with boot2docker...
Copying certs to the local machine directory...
Copying certs to the remote machine...
Setting Docker configuration on the remote daemon...
Checking connection to Docker...
Docker is up and running!
To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: C:\Program Files\Docker Toolbox\docker-machine.exe env vm1

pedro@phantro MINGW64 ~
$

3 - Para iniciar uma docker machine
docker-machine start vm1

4 - Acessando uma docker machine já criada
docker-machine ssh vm1

pedro@phantro MINGW64 ~
$ docker-machine ssh vm1
   ( '>')
  /) TC (\   Core is distributed with ABSOLUTELY NO WARRANTY.
 (/-_--_-\)           www.tinycorelinux.net

docker@vm1:~$

5 - Criando meu primeiro Swarm

    5.1 - Acessar a VM1
    pedro@phantro MINGW64 ~
    $ docker-machine ssh vm1
     ( '>')
    /) TC (\   Core is distributed with ABSOLUTELY NO WARRANTY.
   (/-_--_-\)           www.tinycorelinux.net

    docker@vm1:~$

    5.2 - Comando para iniciar o Swarm
    docker@vm1:~$ docker swarm init
    Error response from daemon: could not choose an IP address to advertise since this system has multiple addresses
    on different interfaces (10.0.2.15 on eth0 and 192.168.99.101 on eth1) - specify one with --advertise-addr
    docker@vm1:~$

    É necessário escolher a interface    

    docker@vm1:~$ docker swarm init --advertise-addr 192.168.99.101
    Swarm initialized: current node (trnld9swx304s0qmbsk3roer8) is now a manager.

    To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-49rrfgce552b1d4mb9v8h8rn7sgpz0trjqwxctl4pqvs4gqnhu-35mith8eyx4nuy0xobquphtye 192.168.99.101:2377

    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

    docker@vm1:~$

    5.3 - Para obter informações sobre o nó
    docker@vm1:~$ docker info
    Client:
    Debug Mode: false

    Server:
    Containers: 0
    Running: 0
    Paused: 0
    Stopped: 0
    Images: 0
    Server Version: 19.03.5
    Storage Driver: overlay2
    Backing Filesystem: extfs
    Supports d_type: true
    Native Overlay Diff: true
    Logging Driver: json-file
    Cgroup Driver: cgroupfs
    Plugins:
    Volume: local
    Network: bridge host ipvlan macvlan null overlay
    Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
    Swarm: active
    NodeID: trnld9swx304s0qmbsk3roer8
    Is Manager: true
    ClusterID: siogtj74jon41qlue7bllishw
    Managers: 1
    Nodes: 1
    Default Address Pool: 10.0.0.0/8
    SubnetSize: 24
    Data Path Port: 4789
    Orchestration:
    Task History Retention Limit: 5
    Raft:
    Snapshot Interval: 10000
    Number of Old Snapshots to Retain: 0
    Heartbeat Tick: 1
    Election Tick: 10
    Dispatcher:
    Heartbeat Period: 5 seconds
    CA Configuration:
    Expiry Duration: 3 months
    Force Rotate: 0
    Autolock Managers: false
    Root Rotation In Progress: false
    Node Address: 192.168.99.101
    Manager Addresses:
    192.168.99.101:2377
    Runtimes: runc
    Default Runtime: runc
    Init Binary: docker-init
    containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339
    runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657
    init version: fec3683
    Security Options:
    seccomp
    Profile: default
    Kernel Version: 4.14.154-boot2docker
    Operating System: Boot2Docker 19.03.5 (TCL 10.1)
    OSType: linux
    Architecture: x86_64
    CPUs: 1
    Total Memory: 989.5MiB
    Name: vm1
    ID: HKGG:QRP4:TS3U:47PB:DWHU:R5PM:2A5Y:2VIP:DET2:46QB:2NXV:DOH3
    Docker Root Dir: /mnt/sda1/var/lib/docker
    Debug Mode: false
    Registry: https://index.docker.io/v1/
    Labels:
    provider=virtualbox
    Experimental: false
    Insecure Registries:
    127.0.0.0/8
    Live Restore Enabled: false
    Product License: Community Engine

    docker@vm1:~$

6 - Criando os workers do meu primeiro Swarm

    6.1 - Criar as VMs nós
    docker-machine create -d virtualbox vm2
    docker-machine create -d virtualbox vm3
    docker-machine create -d virtualbox vm4
    docker-machine create -d virtualbox vm5

    pedro@phantro MINGW64 ~
    $ docker-machine create -d virtualbox vm2
    Running pre-create checks...
    Creating machine...
    (vm2) Copying C:\Users\pedro\.docker\machine\cache\boot2docker.iso to C:\Users\pedro\.docker\machine\machines\vm2\boot2docker.iso...
    (vm2) Creating VirtualBox VM...
    (vm2) Creating SSH key...
    (vm2) Starting the VM...
    (vm2) Check network to re-create if needed...
    (vm2) Windows might ask for the permission to configure a dhcp server. Sometimes, such confirmation window is minimized in the taskbar.
    (vm2) Waiting for an IP...
    Waiting for machine to be running, this may take a few minutes...
    Detecting operating system of created instance...
    Waiting for SSH to be available...
    Detecting the provisioner...
    Provisioning with boot2docker...
    Copying certs to the local machine directory...
    Copying certs to the remote machine...
    Setting Docker configuration on the remote daemon...
    Checking connection to Docker...
    Docker is up and running!
    To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: C:\Program Files\Docker Toolbox\docker-machine.exe env vm2

    pedro@phantro MINGW64 ~

    pedro@phantro MINGW64 ~
    $ docker-machine create -d virtualbox vm3
    Running pre-create checks...
    Creating machine...
    (vm3) Copying C:\Users\pedro\.docker\machine\cache\boot2docker.iso to C:\Users\pedro\.docker\machine\machines\vm3\boot2docker.iso...
    (vm3) Creating VirtualBox VM...
    (vm3) Creating SSH key...
    (vm3) Starting the VM...
    (vm3) Check network to re-create if needed...
    (vm3) Windows might ask for the permission to configure a dhcp server. Sometimes, such confirmation window is minimized in the taskbar.
    (vm3) Waiting for an IP...
    Waiting for machine to be running, this may take a few minutes...
    Detecting operating system of created instance...
    Waiting for SSH to be available...
    Detecting the provisioner...
    Provisioning with boot2docker...
    Copying certs to the local machine directory...
    Copying certs to the remote machine...
    Setting Docker configuration on the remote daemon...
    Checking connection to Docker...
    Docker is up and running!
    To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: C:\Program Files\Docker Toolbox\docker-machine.exe env vm3

    pedro@phantro MINGW64 ~

    pedro@phantro MINGW64 ~
    $ docker-machine ls
    NAME      ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
    default   *        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5
    vm1       -        virtualbox   Running   tcp://192.168.99.101:2376           v19.03.5
    vm2       -        virtualbox   Running   tcp://192.168.99.102:2376           v19.03.5
    vm3       -        virtualbox   Running   tcp://192.168.99.103:2376           v19.03.5

    pedro@phantro MINGW64 ~
    $

    6.2 - Adicionar os workers
    
    A) Adicionando o worker VM2
    docker@vm2:~$ docker swarm join --token SWMTKN-1-49rrfgce552b1d4mb9v8h8rn7sgpz0trjqwxctl4pqvs4gqnhu-35mith8eyx4nuy0xobquphtye 192.168.99.101:2377
    This node joined a swarm as a worker.
    docker@vm2:~$

    B) Adicionando o worker VM3
    pedro@phantro MINGW64 ~
    $ docker-machine ssh vm3
    ( '>')
    /) TC (\   Core is distributed with ABSOLUTELY NO WARRANTY.
    (/-_--_-\)           www.tinycorelinux.net

    <gqnhu-35mith8eyx4nuy0xobquphtye 192.168.99.101:2377
    This node joined a swarm as a worker.
    docker@vm3:~$

7 - Comando para exibir o token

Acessar o nó master:
docker-machine ssh vm1

Comando:
docker swarm join-token worker


8 - Listando os workers do meu swarm
docker node ls
docker@vm1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
trnld9swx304s0qmbsk3roer8 *   vm1                 Ready               Active              Leader              19.03.5
zjg7tbxqe5lkts03qayhgfby3     vm2                 Ready               Active                                  19.03.5
vmr3fksm2d8xbioaf28tak8b8     vm3                 Ready               Active                                  19.03.5
docker@vm1:~$


9 - Removendo um worker do meu swarm
docker node rm <id do worker>

docker@vm1:~$ docker node rm vmr3fksm2d8xbioaf28tak8b8
Error response from daemon: rpc error: code = FailedPrecondition desc = node vmr3fksm2d8xbioaf28tak8b8 is not down and can't be removed
docker@vm1:~$

O worker só poderá ser removido se estiver com STATUS Down. Para isso, basta acessar o nó a ser removido (vm3) e
usar o comando "docker swarm leave".
docker@vm3:~$ docker swarm leave
Node left the swarm.
docker@vm3:~$


Voltando para o nó manager, basta digitar o comando para remover o nó.

docker@vm1:~$ docker node rm vmr3fksm2d8xbioaf28tak8b8
vmr3fksm2d8xbioaf28tak8b8
docker@vm1:~$

Verificando o Swarm após a remoção
docker@vm1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
trnld9swx304s0qmbsk3roer8 *   vm1                 Ready               Active              Leader              19.03.5
zjg7tbxqe5lkts03qayhgfby3     vm2                 Ready               Active                                  19.03.5
docker@vm1:~$

10 - Executando o primeiro container

No contexto local, seria executado o comando:
docker container run -p 8080:3000 -d aluracursos/barbearia

docker@vm2:~$ docker container run -p 8080:3000 -d aluracursos/barbearia
Unable to find image 'aluracursos/barbearia:latest' locally
latest: Pulling from aluracursos/barbearia
8f91359f1fff: Pull complete
3bfc330579f6: Pull complete
dc642667e98e: Pull complete
e2b98a2a2ac3: Pull complete
03b3e44f7cb8: Pull complete
917f35e75662: Pull complete
d05680ac0055: Pull complete
b1ac2108d32f: Pull complete
Digest: sha256:888b472a59897796fa7ef82544db226d43abb3d312483442fa548d632a0df563
Status: Downloaded newer image for aluracursos/barbearia:latest
5f6595fe01c31792b26cdd9633a181a645fb481e77886e101498e62af859c7e0
docker@vm2:~$

docker@vm2:~$ docker container ls
CONTAINER ID        IMAGE                   COMMAND                  CREATED             STATUS              PORTS                    NAMES
5f6595fe01c3        aluracursos/barbearia   "/bin/sh -c 'node se…"   52 seconds ago      Up 51 seconds       0.0.0.0:8080->3000/tcp   dreamy_tesla
docker@vm2:~$


Removendo o container recém alocado:

docker container ls

docker container rm <id do container> --force

docker@vm2:~$ docker container ls
CONTAINER ID        IMAGE                   COMMAND                  CREATED             STATUS              PORTS                    NAMES
5f6595fe01c3        aluracursos/barbearia   "/bin/sh -c 'node se…"   52 seconds ago      Up 51 seconds       0.0.0.0:8080->3000/tcp   dreamy_tesla
docker@vm2:~$ docker container ls
CONTAINER ID        IMAGE                   COMMAND                  CREATED             STATUS              PORTS                    NAMES
5f6595fe01c3        aluracursos/barbearia   "/bin/sh -c 'node se…"   11 minutes ago      Up 11 minutes       0.0.0.0:8080->3000/tcp   dreamy_tesla
docker@vm2:~$
docker@vm2:~$
docker@vm2:~$ docker container rm 5f6595fe01c3 --force
5f6595fe01c3
docker@vm2:~$ docker container ls
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
docker@vm2:~$


Para criar o container no contexto do Swarm, deve-se especificar um serviço e só pode ser executado no nó manager:
docker service create -p 8080:3000 aluracursos/barbearia
docker@vm1:~$ docker service create -p 8080:3000 aluracursos/barbearia
lcsaai6vp88xq6krr91w1awxj
overall progress: 1 out of 1 tasks
1/1: running   [==================================================>]
verify: Service converged
docker@vm1:~$

Verificando o status do serviço recém criado.
docker@vm1:~$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                          PORTS
lcsaai6vp88x        nostalgic_hypatia   replicated          1/1                 aluracursos/barbearia:latest   *:8080->3000/tcp
docker@vm1:~$

Verificando a task recém criada
docker service ps lcsaai6vp88x

docker@vm1:~$ docker service ps lcsaai6vp88x
ID                  NAME                  IMAGE                          NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS
thhjx9z0786h        nostalgic_hypatia.1   aluracursos/barbearia:latest   vm2                 Running             Running 19 minutes ago
docker@vm1:~$

Verificando no nó VM2 é possível ver que o serviço criado foi orquestrado e está executando o container no worker VM2
docker@vm2:~$ docker container ls
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS              PORTS               NAMES
5bd437228b8d        aluracursos/barbearia:latest   "/bin/sh -c 'node se…"   35 seconds ago      Up 34 seconds                           nostalgic_hypatia.1.thhjx9z0786hsx6mtlzikfmez
docker@vm2:~$

docker@vm3:~$ docker container ls
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
docker@vm3:~$




11 - Comando para verificar informações dos nós
docker node inspect vm2

docker@vm1:~$
docker@vm1:~$ docker node inspect vm2
[
    {
        "ID": "zjg7tbxqe5lkts03qayhgfby3",
        "Version": {
            "Index": 15
        },
        "CreatedAt": "2020-06-23T14:46:57.819787995Z",
        "UpdatedAt": "2020-06-23T14:46:57.861005634Z",
        "Spec": {
            "Labels": {},
            "Role": "worker",
            "Availability": "active"
        },
        "Description": {
            "Hostname": "vm2",
            "Platform": {
                "Architecture": "x86_64",
                "OS": "linux"
            },
            "Resources": {
                "NanoCPUs": 1000000000,
                "MemoryBytes": 1037537280
            },
            "Engine": {
                "EngineVersion": "19.03.5",
                "Labels": {
                    "provider": "virtualbox"
                },
                "Plugins": [
                    {
                        "Type": "Log",
                        "Name": "awslogs"
                    },
                    {
                        "Type": "Log",
                        "Name": "fluentd"
                    },
                    {
                        "Type": "Log",
                        "Name": "gcplogs"
                    },
                    {
                        "Type": "Log",
                        "Name": "gelf"
                    },
                    {
                        "Type": "Log",
                        "Name": "journald"
                    },
                    {
                        "Type": "Log",
                        "Name": "json-file"
                    },
                    {
                        "Type": "Log",
                        "Name": "local"
                    },
                    {
                        "Type": "Log",
                        "Name": "logentries"
                    },
                    {
                        "Type": "Log",
                        "Name": "splunk"
                    },
                    {
                        "Type": "Log",
                        "Name": "syslog"
                    },
                    {
                        "Type": "Network",
                        "Name": "bridge"
                    },
                    {
                        "Type": "Network",
                        "Name": "host"
                    },
                    {
                        "Type": "Network",
                        "Name": "ipvlan"
                    },
                    {
                        "Type": "Network",
                        "Name": "macvlan"
                    },
                    {
                        "Type": "Network",
                        "Name": "null"
                    },
                    {
                        "Type": "Network",
                        "Name": "overlay"
                    },
                    {
                        "Type": "Volume",
                        "Name": "local"
                    }
                ]
            },
            "TLSInfo": {
                "TrustRoot": "-----BEGIN CERTIFICATE-----\nMIIBazCCARCgAwIBAgIUIY3oKoWP5s7RpCvuVYAO/AHvRm8wCgYIKoZIzj0EAwIw\nEzERMA8GA1UEAxMIc3dhcm0tY2EwHhcNMjAwNjIzMTQyNTAwWhcNNDAwNjE4MTQy\nNTAwWjATMREwDwYDVQQDEwhzd2FybS1jYTBZMBMGByqGSM49AgEGCCqGSM49AwEH\nA0IABPW3kyVuXfCEEnPjoJJLLPnZqAt6pepMD/we5bx18wahVBz16WiLMdT7rV/M\njidAHlVNpw772qp65sA77OwdCX+jQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBRuKh0UpgAKiYqYJLk1hCgF8aUcNTAKBggqhkjO\nPQQDAgNJADBGAiEAg/8QA7a9fucT23DNlED6D2y1lGU3VNydoeoXB2AClqICIQDT\nTdz4UXJONx61RgwNR1tUCPdhGF9TgUkQKm56AgvzCw==\n-----END CERTIFICATE-----\n",
                "CertIssuerSubject": "MBMxETAPBgNVBAMTCHN3YXJtLWNh",
                "CertIssuerPublicKey": "MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE9beTJW5d8IQSc+Ogkkss+dmoC3ql6kwP/B7lvHXzBqFUHPXpaIsx1PutX8yOJ0AeVU2nDvvaqnrmwDvs7B0Jfw=="
            }
        },
        "Status": {
            "State": "ready",
            "Addr": "192.168.99.102"
        }
    }
]
docker@vm1:~$

12 - Tarefas de Routing e Mesh 

As requisições que chegam ao contexto swarm são redicionadas para as portas dos containers.

                    ===========> 192.168.99.101:8080
                    ||
    8080 ===> ROUTING MESH ====> 192.168.99.102:8080
                    ||
                    ===========> 192.168.99.103:8080

Exercício:
Qual artifício do Docker Swarm permite que nós possamos acessar quaisquer serviços a partir do IP de qualquer nó dentro do swarm, apenas informando a porta?
Alternativa correta! Graças ao Routing Mesh conseguimos acessar diferentes serviços a partir de qualquer IP pertencente ao swarm.

Ao parar um container local ele é orquestrado para outro nó:

docker@vm2:~$ docker container ls
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS              PORTS               NAMES
5bd437228b8d        aluracursos/barbearia:latest   "/bin/sh -c 'node se…"   35 seconds ago      Up 34 seconds                           nostalgic_hypatia.1.thhjx9z0786hsx6mtlzikfmez
docker@vm2:~$ docker container rm 5bd437228b8d --force
5bd437228b8d
docker@vm2:~$

O conteainer foi orquestrado para o worker 2 novamente:
docker@vm1:~$ docker service ps lcsaai6vp88x
ID                  NAME                      IMAGE                          NODE                DESIRED STATE       CURRENT STATE                ERROR                         PORTS
9135v8a67z3p        nostalgic_hypatia.1       aluracursos/barbearia:latest   vm2                 Running             Running about a minute ago
thhjx9z0786h         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   vm2                 Shutdown            Failed about a minute ago    "task: non-zero exit (137)"
docker@vm1:~$


13 - Parando as VMs

pedro@phantro MINGW64 ~
$ docker-machine ls
NAME      ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS
default   *        virtualbox   Running   tcp://192.168.99.100:2376           v19.03.5
vm1       -        virtualbox   Running   tcp://192.168.99.101:2376           v19.03.5
vm2       -        virtualbox   Running   tcp://192.168.99.102:2376           v19.03.5
vm3       -        virtualbox   Running   tcp://192.168.99.103:2376           v19.03.5

pedro@phantro MINGW64 ~
$ docker-machine stop default
Stopping "default"...
Machine "default" was stopped.

pedro@phantro MINGW64 ~
$ docker-machine stop vm1
Stopping "vm1"...
Machine "vm1" was stopped.

pedro@phantro MINGW64 ~
$ docker-machine stop vm2
Stopping "vm2"...
Machine "vm2" was stopped.

pedro@phantro MINGW64 ~
$ docker-machine stop vm3
Stopping "vm3"...
Machine "vm3" was stopped.

pedro@phantro MINGW64 ~
$ docker-machine ls
NAME      ACTIVE   DRIVER       STATE     URL   SWARM   DOCKER    ERRORS
default   -        virtualbox   Stopped                 Unknown
vm1       -        virtualbox   Stopped                 Unknown
vm2       -        virtualbox   Stopped                 Unknown
vm3       -        virtualbox   Stopped                 Unknown

pedro@phantro MINGW64 ~
$


14 - Como fazer backup do Swarm 

VM1 - Manager
cd /var/lib/docker/swarm

docker@vm1:~$ sudo su
root@vm1:/home/docker# cd /var/lib/docker/swarm/
root@vm1:/var/lib/docker/swarm#
root@vm1:/var/lib/docker/swarm#
root@vm1:/var/lib/docker/swarm# ls
certificates       raft               worker
docker-state.json  state.json
root@vm1:/var/lib/docker/swarm#

Caso os nós sejam removidos basta restaurar o conteudo do diretório

Copiar os arquivos de backup para /var/lib/docker/swarm/
cp -r backup/* /var/lib/docker/swarm/

Iniciar o cluster com o parametro "--force-new-cluster" para carregar os arquivos salvos em /var/lib/docker/swarm/
docker swarm init --force-new-cluster --advertise-addr 192.168.99.112

15 - Criando mais managers

No manager VM identificar o token para adicionar novos managers no SWARM
docker swarm join-token manager

docker@vm1:~$ docker swarm join-token manager
To add a manager to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-49rrfgce552b1d4mb9v8h8rn7sgpz0trjqwxctl4pqvs4gqnhu-dczn0ont8ua95h41us671grsh 192.168.99.101:2377

docker@vm1:~$

Para formatar saída do comando com a opção --format:
docker node ls --format "{{.Hostname}} {{.ManagerStatus}}"
vm1 Leader
vm2 Reachable
vm2
vm3 Reachable
vm3
vm4
vm5

docker node ls --format "{{.Hostname}} {{.Status}} {{.ManagerStatus}}"
vm1 Ready Leader (Manager e Líder)
vm2 Ready Reachable (Manager)
vm2 Down
vm3 Ready Reachable (Manager)
vm3 Down
vm4 Ready
vm5 Ready

Removendo nós não utilizados com status "Down"
docker@vm1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
trnld9swx304s0qmbsk3roer8 *   vm1                 Ready               Active              Leader              19.03.5
zke1wht8zjq2fmjwaj637emty     vm2                 Ready               Active              Reachable           19.03.5
zjg7tbxqe5lkts03qayhgfby3     vm2                 Down                Active                                  19.03.5
opfmg2f434a0ketavd0x1hku7     vm3                 Ready               Active              Reachable           19.03.5
pk03xo0a2651r9g35apmr4h5t     vm3                 Down                Active                                  19.03.5
hrbqkdkcyik3lxc2wsylec69l     vm4                 Ready               Active                                  19.03.5
f03s69shr0309sj3qa3hmp67i     vm5                 Ready               Active                                  19.03.5
docker@vm1:~$ docker node rm zjg7tbxqe5lkts03qayhgfby3
zjg7tbxqe5lkts03qayhgfby3
docker@vm1:~$ docker node rm pk03xo0a2651r9g35apmr4h5t
pk03xo0a2651r9g35apmr4h5t
docker@vm1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
trnld9swx304s0qmbsk3roer8 *   vm1                 Ready               Active              Leader              19.03.5
zke1wht8zjq2fmjwaj637emty     vm2                 Ready               Active              Reachable           19.03.5
opfmg2f434a0ketavd0x1hku7     vm3                 Ready               Active              Reachable           19.03.5
hrbqkdkcyik3lxc2wsylec69l     vm4                 Ready               Active                                  19.03.5
f03s69shr0309sj3qa3hmp67i     vm5                 Ready               Active                                  19.03.5


15 - Algoritmo de Consenso Raft

Regras para eleição de novo líder do Swarm

Suporta (N-1)/2 falhas

Deve ter no mínimo  N/2 + 1 de quórum

Onde N = Número de Managers

Recomendação do Docker = 3, 5 ou 7 Managers nunca acima de 10 por questão de desempenho

Para 7 nós managers teríamos:
3 Falhas
4 Quorum

16 - Separando as responsabilidades

Para remover um nó manager do swarm temos 2 passos:
1 - docker node demote vm1 (Rebaixar o nó)
2 - docker node rm vm1 (Remove nó)

17 - Alterando a disponibilidade de um manager

Parando serviços em execução 
docker service rm $(docker service -q)

Restrigindo Nós:
docker@vm1:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
trnld9swx304s0qmbsk3roer8 *   vm1                 Ready               Active              Leader              19.03.5
zke1wht8zjq2fmjwaj637emty     vm2                 Ready               Active              Reachable           19.03.5
opfmg2f434a0ketavd0x1hku7     vm3                 Ready               Active              Reachable           19.03.5
hrbqkdkcyik3lxc2wsylec69l     vm4                 Ready               Active                                  19.03.5
f03s69shr0309sj3qa3hmp67i     vm5                 Ready               Active                                  19.03.5
docker@vm1:~$

Comanado:
docker@vm1:~$ docker node update --availability drain 

Restrigindo Serviços:
docker service update --constraint-add node.role==worker

docker service update --constraint-add node.role==worker lcsaai6vp88x

docker@vm1:~$ docker service ps lcsaai6vp88x
ID                  NAME                      IMAGE                          NODE                        DESIRED STATE       CURRENT STATE          ERROR                         PORTS
nzlrqksc46gk        nostalgic_hypatia.1       aluracursos/barbearia:latest   vm1                         Running             Running 2 hours ago
9135v8a67z3p         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   zjg7tbxqe5lkts03qayhgfby3   Shutdown            Shutdown 2 hours ago
thhjx9z0786h         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   zjg7tbxqe5lkts03qayhgfby3   Shutdown            Failed 2 days ago      "task: non-zero exit (137)"
docker@vm1:~$ docker service update --constraint-add node.role==worker lcsaai6vp88x
lcsaai6vp88x
overall progress: 1 out of 1 tasks
1/1: running   [==================================================>]
verify: Service converged
docker@vm1:~$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                          PORTS
lcsaai6vp88x        nostalgic_hypatia   replicated          1/1                 aluracursos/barbearia:latest   *:8080->3000/tcp
docker@vm1:~$ docker service ps lcsaai6vp88x
ID                  NAME                      IMAGE                          NODE                        DESIRED STATE       CURRENT STATE             ERROR                         PORTS
1sdbwor05x1b        nostalgic_hypatia.1       aluracursos/barbearia:latest   vm4                         Running             Running 19 minutes ago
nzlrqksc46gk         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   vm1                         Shutdown            Shutdown 19 minutes ago
9135v8a67z3p         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   zjg7tbxqe5lkts03qayhgfby3   Shutdown            Shutdown 2 hours ago
thhjx9z0786h         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   zjg7tbxqe5lkts03qayhgfby3   Shutdown            Failed 2 days ago         "task: non-zero exit (137)"
docker@vm1:~$


18 - Serviços globais e replicados

docker service update --replicas 5 lcsaai6vp88x
ou
docker service scale lcsaai6vp88x=5

docker@vm1:~$ docker service ps lcs
ID                  NAME                      IMAGE                          NODE                        DESIRED STATE       CURRENT STATE             ERROR                         PORTS
1sdbwor05x1b        nostalgic_hypatia.1       aluracursos/barbearia:latest   vm4                         Running             Running 50 minutes ago
nzlrqksc46gk         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   vm1                         Shutdown            Shutdown 51 minutes ago
9135v8a67z3p         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   zjg7tbxqe5lkts03qayhgfby3   Shutdown            Shutdown 2 hours ago
thhjx9z0786h         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   zjg7tbxqe5lkts03qayhgfby3   Shutdown            Failed 2 days ago         "task: non-zero exit (137)"
d15de51wnn18        nostalgic_hypatia.2       aluracursos/barbearia:latest   vm1                         Running             Running 58 seconds ago
ps3oji3n0t6f        nostalgic_hypatia.3       aluracursos/barbearia:latest   vm3                         Running             Running 29 seconds ago
po722kbqxzhr        nostalgic_hypatia.4       aluracursos/barbearia:latest   vm2                         Running             Running 58 seconds ago
ljkgp7lzskgr        nostalgic_hypatia.5       aluracursos/barbearia:latest   vm5                         Running             Running 30 seconds ago
docker@vm1:~$ docker service update --replicas 8 lcs
lcs
overall progress: 8 out of 8 tasks
1/8: running   [==================================================>]
2/8: running   [==================================================>]
3/8: running   [==================================================>]
4/8: running   [==================================================>]
5/8: running   [==================================================>]
6/8: running   [==================================================>]
7/8: running   [==================================================>]
8/8: running   [==================================================>]
verify: Service converged
docker@vm1:~$ docker service ps lcs
ID                  NAME                      IMAGE                          NODE                        DESIRED STATE       CURRENT STATE                ERROR                         PORTS
1sdbwor05x1b        nostalgic_hypatia.1       aluracursos/barbearia:latest   vm4                         Running             Running 51 minutes ago
nzlrqksc46gk         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   vm1                         Shutdown            Shutdown 51 minutes ago
9135v8a67z3p         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   zjg7tbxqe5lkts03qayhgfby3   Shutdown            Shutdown 2 hours ago
thhjx9z0786h         \_ nostalgic_hypatia.1   aluracursos/barbearia:latest   zjg7tbxqe5lkts03qayhgfby3   Shutdown            Failed 2 days ago            "task: non-zero exit (137)"
d15de51wnn18        nostalgic_hypatia.2       aluracursos/barbearia:latest   vm1                         Running             Running about a minute ago
ps3oji3n0t6f        nostalgic_hypatia.3       aluracursos/barbearia:latest   vm3                         Running             Running about a minute ago
po722kbqxzhr        nostalgic_hypatia.4       aluracursos/barbearia:latest   vm2                         Running             Running about a minute ago
ljkgp7lzskgr        nostalgic_hypatia.5       aluracursos/barbearia:latest   vm5                         Running             Running about a minute ago
l12plilcrk8v        nostalgic_hypatia.6       aluracursos/barbearia:latest   vm2                         Running             Running 8 seconds ago
94fr72c4dkm4        nostalgic_hypatia.7       aluracursos/barbearia:latest   vm3                         Running             Running 8 seconds ago
mhzbi6nkj8xz        nostalgic_hypatia.8       aluracursos/barbearia:latest   vm1                         Running             Running 8 seconds ago
docker@vm1:~$


19 - Criando serviço GLOBAL

docker service create -p 8080:3000 --mode global aluracursos/barbearia

20 - Driver Overlay

Rede do Swarm

docker@vm1:~$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
6f28adc8167b        bridge              bridge              local
82c9cc141aa8        docker_gwbridge     bridge              local
53d2d8c1bd3d        host                host                local
qalvm0qjww2g        ingress             overlay             swarm
4fc185dc0904        none                null                local
docker@vm1:~$

docker service create --name servico --replicas 2 alpine sleep 1d

docker@vm1:~$ docker service create --name servico --replicas 2 alpine sleep 1d
ykqsrkkk715fwyot190cxa69v
overall progress: 2 out of 2 tasks
1/2: running
2/2: running
verify: Service converged
docker@vm1:~$       

Testando o conceito Service Discovery

Criando novo serviço com duas réplicas:
docker@vm1:~$ docker service create --name servico --network my_overlay --replicas 2 alpine sleep 1d
bp3559xv26otujpuufjc8ox1n
overall progress: 2 out of 2 tasks
1/2: running   [==================================================>]
2/2: running   [==================================================>]
verify: Service converged

Verificando em quais nós estão executando o novo servico
docker@vm1:~$ docker service ps bp3559xv26otujpuufjc8ox1n
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE                ERROR               PORTS
ruf1cwpi2n3o        servico.1           alpine:latest       vm4                 Running             Running about a minute ago
qflquojly41c        servico.2           alpine:latest       vm5                 Running             Running about a minute ago
docker@vm1:~$

Verificando se a nova rede overlay my_overlay foi reconhecida no nó VM5
docker@vm5:~$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
19ff57bb99b3        bridge              bridge              local
3365d975e7da        docker_gwbridge     bridge              local
1cf3b80c50e9        host                host                local
qalvm0qjww2g        ingress             overlay             swarm
82h9l9084ffq        my_overlay          overlay             swarm
be5fbee0238f        none                null                local
docker@vm5:~$

docker@vm4:~$ docker container ls
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS              PORTS               NAMES
4c981021e262        alpine:latest                  "sleep 1d"               5 minutes ago       Up 5 minutes                            servico.1.ruf1cwpi2n3oujl51mnazz3hz
cc6ff3d2aed0        aluracursos/barbearia:latest   "/bin/sh -c 'node se…"   3 hours ago         Up 3 hours                              nostalgic_hypatia.1.1sdbwor05x1buw45hozm1c1bk
docker@vm4:~$

docker@vm5:~$ docker container ls
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS              PORTS               NAMES
00588ccb341e        alpine:latest                  "sleep 1d"               5 minutes ago       Up 5 minutes                            servico.2.qflquojly41c13xseby8quof3
25584ec84853        aluracursos/barbearia:latest   "/bin/sh -c 'node se…"   2 hours ago         Up 2 hours                              nostalgic_hypatia.5.ljkgp7lzskgrkvou8gm5wyius
docker@vm5:~$
docker@vm5:~$
docker@vm5:~$ docker exec -it servico.2.qflquojly41c13xseby8quof3 sh
/ #
/ #
/ # ping servico.1.ruf1cwpi2n3oujl51mnazz3hz
PING servico.1.ruf1cwpi2n3oujl51mnazz3hz (10.0.1.3): 56 data bytes
64 bytes from 10.0.1.3: seq=0 ttl=64 time=1.989 ms
64 bytes from 10.0.1.3: seq=1 ttl=64 time=0.511 ms
64 bytes from 10.0.1.3: seq=2 ttl=64 time=0.478 ms
64 bytes from 10.0.1.3: seq=3 ttl=64 time=0.833 ms
64 bytes from 10.0.1.3: seq=4 ttl=64 time=0.532 ms
64 bytes from 10.0.1.3: seq=5 ttl=64 time=0.457 ms
^C
--- servico.1.ruf1cwpi2n3oujl51mnazz3hz ping statistics ---
6 packets transmitted, 6 packets received, 0% packet loss
round-trip min/avg/max = 0.457/0.800/1.989 ms
/ #


Por mais que o driver overlay seja responsável por comunicar múltiplos hosts em uma mesma rede,
também podemos conectar containers em escopo local criados com o comando docker container 
run em redes criadas com esse driver.

Para isso, basta no momento da criação da rede utilizarmos a flag --attachable:

docker network create -d overlay --attachable my_overlay

Com o comando acima, conseguiremos conectar tanto serviços como containers "standalone" em nossa rede my_overlay.

















